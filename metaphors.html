<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc-markdown-css-theme" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>GenLaw: Metaphors</title>
  <link rel="stylesheet" href="css/theme.css" />
  <link rel="stylesheet" href="css/skylighting-paper-theme.css" />
  <link rel="stylesheet" href="css/theme-additions.css" />
<!-- Google Analytics tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-W2ZW2ZM1M6"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-W2ZW2ZM1M6');
</script>
</head>
<body>

<header>
  <h1 class="title">GenLaw: Metaphors</h1>
<div class="metadata">

</div>

</header>

<nav id="TOC" role="doc-toc">
    <input type="checkbox" id="contents">
  <label for="contents">
    <h4 id="toc-heading">
              Contents
            <svg id="toc-chevron" width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path d="M2.08926 3.16074C1.76382 2.83531 1.23618 2.83531 0.910744 3.16074C0.585307 3.48618 0.585307 4.01382 0.910744 4.33926L2.08926 3.16074ZM6 8.25L5.41074 8.83926C5.73618 9.16469 6.26382 9.16469 6.58926 8.83926L6 8.25ZM11.0893 4.33926C11.4147 4.01382 11.4147 3.48618 11.0893 3.16074C10.7638 2.83531 10.2362 2.83531 9.91074 3.16074L11.0893 4.33926ZM0.910744 4.33926L5.41074 8.83926L6.58926 7.66074L2.08926 3.16074L0.910744 4.33926ZM6.58926 8.83926L11.0893 4.33926L9.91074 3.16074L5.41074 7.66074L6.58926 8.83926Z" fill="currentColor"/>
      </svg>
    </h4>
  </label>
  <ul>
  <li><a href="#training" id="toc-training">Models are trained.</a></li>
  <li><a href="#learning" id="toc-learning">Models learn like children do.</a></li>
  <li><a href="#collage" id="toc-collage">Generations are collages.</a></li>
  <li><a href="#parrots" id="toc-parrots">Large language models are stochastic parrots.</a></li>
  <li><a href="#search" id="toc-search">Large language models are noisy search engines.</a></li>
  <li><a href="#references" id="toc-references">References</a></li>
  </ul>
</nav>


<main id="main" class="">
        <p style="text-align:right"><a href="https://genlaw.github.io/">Back to GenLaw ↩︎</a></p>
  <p>We briefly discuss several metaphors for Generative AI that came up in the GenLaw discussions. It is worth considering why these metaphors are helpful and where they start to break down.</p>
<p>See also: <a href="resources.html">resources</a>, <a href="#glossary.html">glossary</a>, and the <a href="2023-report.html">GenLaw Report</a></p>
<h2 id="training">Models are trained.</h2>
<p>Machine-learning practitioners will often say they <strong><a href="glossary.html#training">train</a></strong> <strong><a href="glossary.html#model">models</a></strong>. Training brings to mind teaching a dog to perform tricks by enforcing good behavior with treats. Each time the dog performs the desired behavior, they get a treat. As the dog masters one skill it may move onto another. Model training is similar in the sense that models are optimized to maximize some <strong><a href="glossary.html#reward">reward</a></strong>.<span class="sidenote-wrapper"><label for="sn-0" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-0" class="margin-toggle"/><span class="sidenote">Maximizing a reward is exactly equivalent to minimizing a <strong><a href="glossary.html#loss">loss</a></strong> (except for the extra minus sign), but due to historical reasons, machine-learning practitioners use the latter phrasing more often.<br />
<br />
</span></span> This reward is computed based on how similar the model’s outputs are to desired outputs from the model.</p>
<p>However, unlike training a dog, model training does not typically have a curriculum;<span class="sidenote-wrapper"><label for="sn-1" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-1" class="margin-toggle"/><span class="sidenote">Curriculum learning is an entire field of research in machine learning, but it is not currently standard to use a curriculum.<br />
<br />
</span></span> there is no progression of easier to harder skills to learn, and the formula for computing the reward remains the same throughout model training.</p>
<h2 id="learning">Models learn like children do.</h2>
<p><strong>Learning</strong> is the active verb we use to describe what a <strong><a href="glossary.html#model">model</a></strong> does as it is being <strong><a href="glossary.html#training">trained</a></strong> — a model is <em>trained</em>, and during this process it <em>learns</em>. Model learning is the most common anthropomorphic metaphor applied to machine-learning models. The use of the word <strong>learning</strong> by machine-learning practitioners has naturally led to comparisons between how models learn and how human children do. Both children and machine-learning models are “skilled imitators,” acquiring knowledge of the world by learning to imitate provided exemplars. However, human children and Generative AI obviously use very different mechanisms to learn. Techniques that help generative-AI systems to learn better, such as increasing model size, have no parallels in child development; mechanisms children use to “extract novel and abstract structures from the environment beyond statistical patterns” have no machine-learning comparisons <span class="citation" data-cites="yiu2023imitation">(Yiu, Kosoy, and Gopnik 2023)</span>.</p>
<h2 id="collage">Generations are collages.</h2>
<p>We quote directly from discussion in <span class="citation" data-cites="lee2023talkin">Lee, Cooper, and Grimmelmann (2023, 58)</span>, with added links to our glossary.</p>
<blockquote>
<p>It also may seem intuitively attractive to consider <strong><a href="glossary.html#generation">generations</a></strong> to be analogous to collages. However, while this may seem like a useful metaphor, it can be misleading in several ways. For one, an artist may make a collage by taking several works and splicing them together to form another work. In this sense, a generation is not a collage: a generative-AI system does not take several works and splice them together. Instead, … generative-AI systems are built with <strong><a href="glossary.html#model">models</a></strong> <strong><a href="glossary.html#training">trained</a></strong> on many <strong><a href="glossary.html#examples">data examples</a></strong>. Moreover, those data examples are not explicitly referred back to during the generation process. Instead, the extent that a generation resembles specific data examples is dependent on the model <strong><a href="glossary.html#vector-representation">encoding</a></strong> in its <strong><a href="glossary.html#parameters">parameters</a></strong> what the specific data examples look like, and then effectively recreating them. Ultimately, it is nevertheless possible for a generation to look like a collage of several different data examples; however, it is debatable whether the the process that produced this appearance meets the definition for a collage. There is no author “select[ing], coordinat[ing], or arrang[ing]”<span class="sidenote-wrapper"><label for="sn-2" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-2" class="margin-toggle"/><span class="sidenote">§ 101 (definition of “compilation”).<br />
<br />
</span></span> training examples to produce the resulting generation.</p>
</blockquote>
<h2 id="parrots">Large language models are stochastic parrots.</h2>
<p><span class="citation" data-cites="bender2021parrots">Bender et al. (2021)</span> describe a <strong><a href="glossary.html#llm">large language model</a></strong> as a stochastic parrot, a “system for haphazardly stitching together sequences of linguistic forms it has observed in its vast training data, according to probabilistic information about how they combine, but without any reference to meaning.” Like parrots mimicking the sounds that they hear around them, LLMs repeat the phrases they are exposed to, but have no conception of the human meaning behind these phrases.</p>
<p>This analogy is useful because it references the very real problem of machine-learning models simply outputting their most frequent training data. Critics of the stochastic-parrot analogy say that it undervalues the competencies that state-of-the-art language models have. Some critics take this further and say that these competencies imply models understand meaning in a human-like way <span class="citation" data-cites="piantadosi2022meaning">(Piantadosi and Hill 2022)</span>.<span class="sidenote-wrapper"><label for="sn-3" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-3" class="margin-toggle"/><span class="sidenote">Whether models are human-like, or the outputs are simply “really good” is less pertinent for how generations and inputs should be regulated.<br />
<br />
</span></span> For example, proponents of this analogy might argue that Generative AI passing a difficult standardized exam (such as the Bar Exam <span class="citation" data-cites="katz2023gpt">(Katz et al. 2023)</span> or the GRE <span class="citation" data-cites="gpt4">(OpenAI 2023)</span>) is more about parroting training data than human-like skill.</p>
<h2 id="search">Large language models are noisy search engines.</h2>
<p>A search engine allows users to search for information within a large database using natural language queries. Like a search engine, <strong><a href="glossary.html#llm">large language models</a></strong> also return information in response to a natural language query. However, while a search engine queries the entries in its database and returns the most appropriate ones, a language model does not have direct access to its <strong><a href="glossary.html#datasets">training data</a></strong> and can only make predictions based on the information stored in the model <strong><a href="glossary.html#weights">weights</a></strong>.<span class="sidenote-wrapper"><label for="sn-4" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-4" class="margin-toggle"/><span class="sidenote">The training data is seen during training, but models are used separately from the training data.<br />
<br />
</span></span> Most often the output will be a mixture of information contained in many database entries. Some model outputs may quote directly from relevant entries in the database (in the case of <strong><a href="glossary.html#memorization">memorization</a></strong>), but this is not reflective of the most typical outputs.</p>
<p>Sometimes <strong><a href="glossary.html#generation">generations</a></strong> from an LLM will convey similar information that one might learn from running a search; however, sometimes it will not because the underlying <strong><a href="glossary.html#algorithm">algorithm</a></strong> is different. Thus, while some generations answer the <strong><a href="glossary.html#prompt">prompt</a></strong> in a similar way to a search, we can more generally think of generative-model outputs as a noisy version of what is actually in the database. Currently, such outputs also tend to lack attribution to the original data entries, and sometimes are incorrect.</p>
<h1 class="unnumbered" id="references">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-bender2021parrots" class="csl-entry" role="listitem">
Bender, Emily M., Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. 2021. <span>“<span class="nocase">On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?</span>”</span> In <em>Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency</em>, 610–23. FAccT ’21. New York, NY, USA: Association for Computing Machinery. <a href="https://doi.org/10.1145/3442188.3445922">https://doi.org/10.1145/3442188.3445922</a>.
</div>
<div id="ref-katz2023gpt" class="csl-entry" role="listitem">
Katz, Daniel Martin, Michael James Bommarito, Shang Gao, and Pablo Arredondo. 2023. <span>“GPT-4 Passes the Bar Exam.”</span> <em>Social Science Research Network 4389233</em>.
</div>
<div id="ref-lee2023talkin" class="csl-entry" role="listitem">
Lee, Katherine, A. Feder Cooper, and James Grimmelmann. 2023. <span>“<span class="nocase">Talkin’ ’Bout AI Generation: Copyright and the Generative-AI Supply Chain</span>.”</span> <em>arXiv Preprint arXiv:2309.08133</em>.
</div>
<div id="ref-gpt4" class="csl-entry" role="listitem">
OpenAI. 2023. <span>“GPT-4 Technical Report.”</span> <em>arXiv Preprint arXiv:2303.08774</em>.
</div>
<div id="ref-piantadosi2022meaning" class="csl-entry" role="listitem">
Piantadosi, Steven T, and Felix Hill. 2022. <span>“Meaning Without Reference in Large Language Models.”</span> <em>arXiv Preprint arXiv:2208.02957</em>.
</div>
<div id="ref-yiu2023imitation" class="csl-entry" role="listitem">
Yiu, Eunice, Eliza Kosoy, and Alison Gopnik. 2023. <span>“Imitation Versus Innovation: What Children Can Do That Large Language and Language-and-Vision Models Cannot (Yet)?”</span> <em>arXiv Preprint arXiv:2305.07666</em>.
</div>
</div>
</main>

<footer>
<p class="signoff">
  <a href="https://genlaw.github.io/">← GenLaw</a>
</p>
</footer>

<script>
document.addEventListener("DOMContentLoaded", function () {
    // Non-essential if user has JavaScript off. Just hides TOC button on scroll.
    const nav = document.querySelector("nav");
    let lastScrollTop = 0;
    const min_diff_px = 32;
    
    function didScroll() {
        const currentScrollTop = window.pageYOffset || document.documentElement.scrollTop;
        if (currentScrollTop < lastScrollTop) {
            nav.classList.add("scrolled-up");
            nav.classList.remove("scrolled-down");
            lastScrollTop = currentScrollTop;
        } else if (currentScrollTop > lastScrollTop + min_diff_px) {
            nav.classList.remove("scrolled-up");
            nav.classList.add("scrolled-down");
            lastScrollTop = currentScrollTop;
        }
    }

    window.addEventListener("scroll", didScroll);
});
  
document.addEventListener("DOMContentLoaded", function () {
    const headings = document.querySelectorAll('main h1, main h2, main h3, main h4');

    function handleIntersection(entries) {
        //  IntersectionObserver's entries are ordered by their position in the DOM tree
        const topmostEntry = entries.find(entry => entry.isIntersecting);
        console.log(topmostEntry)
        if (!topmostEntry) return;

        const tocElementId = 'toc-' + topmostEntry.target.id;
        const tocElement = document.getElementById(tocElementId);
        if (!tocElement) return;

        const otherTocElements = document.querySelectorAll('.active');
        otherTocElements.forEach(el => el.classList.remove('active'));
        tocElement.classList.add('active');
    }

    // root: null -> entire browser viewport
    const options = {
        root: null,
        rootMargin: '0px',
        threshold: 0.8
    };
    const observer = new IntersectionObserver(handleIntersection, options);

    headings.forEach(heading => {
        observer.observe(heading);
    });

    // Manually trigger the IntersectionObserver callback for the initial state
    const initialEntries = Array.from(headings).map(heading => ({
        isIntersecting: heading.getBoundingClientRect().top < window.innerHeight && heading.getBoundingClientRect().bottom > 0,
        target: heading
    }));
    handleIntersection(initialEntries);
});
document.addEventListener('DOMContentLoaded', function() {
    const nav_anchors = document.querySelectorAll('nav a');
    const contents_checkbox = document.getElementById('contents');
  
    nav_anchors.forEach(anchor => {
      anchor.addEventListener('click', function(event) {
        // Do not stop normal functionality of the anchor tag
        // event.preventDefault();
  
        // Uncheck the input with id "contents"
        if (contents_checkbox && contents_checkbox.type === 'checkbox') {
          contents_checkbox.checked = false;
        }
      });
    });
  });
  
document.addEventListener('DOMContentLoaded', () => {
  const headings = document.querySelectorAll('main h1[id], main h2[id], main h3[id], main h4[id], main h5[id], main h6[id]');

  headings.forEach(heading => {
    heading.addEventListener('click', event => {
      const target = event.target;

      if (target.tagName.toLowerCase().startsWith('h') && target.hasAttribute('id')) {
        const headingId = target.getAttribute('id');
        const url = new URL(window.location.href);
        url.hash = headingId;

        navigator.clipboard.writeText(url.toString())
          .then(() => {
            console.log('Heading URL copied to clipboard:', url.toString());
            target.classList.add('copy-success');
            target.setAttribute('title', 'Copied URL to clipboard! ✅');
            setTimeout(() => {
              target.classList.remove('copy-success');
              target.removeAttribute('title');
            }, 3000);

          })
          .catch(err => {
            console.error('Failed to copy the heading URL:', err);
            target.classList.add('copy-error');
            target.setAttribute('title', 'Failed to copy URL! ❌');
            setTimeout(() => {
              target.classList.remove('copy-error');
              target.removeAttribute('title');
            }, 3000);

          });
      }
    });
  });
});
</script>

</body>
</html>

---
title: "The Center for Generative AI, Law, and Policy Research"
subtitle: "The GenLaw Center"
lang: en-US
main-id: index
toc-title: ""
toc: true
return-genlaw: false
return-footer: false
---

<table style="border: none;">
  <tr style="border: none;">
    <td style="border: none;" width="33%" font-size="var(--text-size)">
        <center>
              <img width="150px" alt="Robots reading" src="./images/robots-square.png">
        </center>
    </td>

    <td style="border: none; font-size: 100%;">
      A home for education and research on system evaluations centering policy considerations

      The GenLaw Center directly addresses technical and social challenges raised by generative-AI systems. We craft meaningful metrics and measurement methodologies that scale reliably to the magnitude of current and future systems. Our work provides a grounded scientific basis for understanding the behavior of generative-AI models and, in turn, suggests tunable dials for instructing models to align their behaviors with desired outcomes. To achieve this vision, The GenLaw Center fosters close collaborations between computer scientists, legal scholars, and civil society.

      Our team has done groundbreaking in the creation of generative-AI models, development of the field of AI security, and the design of scalable machine-learning algorithms and metrics. Together, we have founded a new research field: Generative AI and Law. The GenLaw Center is committed to supporting the growth and development of this field through public education and academic mentorship, as well as hosting workshops and directly supporting researchers.

      [[Twitter](https://twitter.com/genlawcenter)]
    </td>
  </tr>
</table>


# Workshop: [Evaluating Generative AI Systems](https://dc-workshop.genlaw.org/)

"Evaluating Generative AI Systems: the Good, the Bad, and the Hype"

The GenLaw Center is co-hosting a workshop in DC ([livestreamed](https://dc-workshop.genlaw.org/livestream) and recorded) on evaluating generative AI systems on Monday, April 15th.
We will discuss the misconceptions between the technical capabilities of evaluating generative AI, and what policymakers and civil society want. Topics covered include:
1) training-data attribution 
2) privacy 
3) data provenance & watermarks 
4) trust & safety.

This event is generously sponsored by the [The K&L Gates Initiative in Ethics and Computational Technologies at CMU](https://www.cmu.edu/ethics-ai/), and co-hosted with the K&L Gates Initiative, [Georgetown Institute for Technology Law & Policy](https://www.law.georgetown.edu/tech-institute/), and [Center for Democracy and Technology](https://cdt.org/).

[[Website](https://dc-workshop.genlaw.org/)]

# Writing

- "Report of the 1st Workshop on Generative AI and Law" [[blog](2023-report.html)][[full report](2023-full-report.html)]
- "The Devil is in the Training Data" [[blog](explainers/training-data.html)] (an [explainer](explainers/index.html) series)
- "Talkin' 'Bout AI Generation: Copyright and the Generative-AI Supply Chain" July 2023. (law review article, to appear at the  *[Journal of the Copyright Society](https://copyrightsociety.org/journal-entries/)*) [[blog](https://genlaw.github.io/explainers/talkin.html)][[ssrn](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4523551)]

# ICML 2023 Workshop

- [Website](2023-workshop.html)
- [Livestream](https://www.youtube.com/watch?v=5j4U2UzJWfI)
- [Liveblog](https://3d.laboratorium.net/2023-07-29-genlaw)  
- [Accepted Papers](papers.html)
    
# Resources
- [Glossary](glossary.html)
- [Metaphors](metaphors.html)
- [Suggested reading](resources.html)


---
title: "GenLaw '23: Resources"
lang: en-US
---

## Ongoing litigation

* [GitHub Copilot litigation](https://githubcopilotlitigation.com/)
* [Stable Diffusion litigation](https://stablediffusionlitigation.com/)

## Legal
### Copyright


* “[Artificial Intelligence’s Fair Use Crisis](https://www.bensobel.org/files/articles/41.1_Sobel-FINAL.pdf)” by Ben Sobel (2017)
* “[Foundation Models and Fair Use](https://arxiv.org/abs/2303.15715)” by Peter Henderson, Xuechen Li, Dan Jurafsky, Tatsunori Hashimoto, Mark A. Lemley, and Percy Liang (2023)
* “[LIBRARY OF CONGRESS Copyright Office 37 CFR Part 202 Copyright Registration Guidance: Works Containing Material Generated by Art](https://public-inspection.federalregister.gov/2023-05321.pdf)” (2023)
* “[Fair Learning](https://texaslawreview.org/fair-learning/)” by Mark A. Lemley and Bryan Casey (2021)
* "[How Copyright Law Can Fix Artificial Intelligence's Implicit Bias Problem](https://digitalcommons.law.uw.edu/wlr/vol93/iss2/2)" by Amanda Levendowski (2018)
* “[There’s No Such Thing as a Computer-Authored Work— And It's a Good Thing, Too](https://james.grimmelmann.net/files/articles/computer-authored-works.pdf)” by James Grimmelmann (2016)

### Privacy:


* “[A taxonomy of privacy](https://scholarship.law.upenn.edu/cgi/viewcontent.cgi?article=1376&context=penn_law_review)” by Daniel Solove (2006) 
* “[Privacy Harms](https://heinonline.org/HOL/LandingPage?handle=hein.journals/bulr102&div=20&id=&page=)” by Danielle Citron and Daniel Solove (2022) 
* “[Deep Fakes: A Looming Challenge for Privacy, Democracy, and National Security](https://heinonline.org/HOL/LandingPage?handle=hein.journals/calr107&div=51&id=&page=)” by Bobby Chesney and Danielle Citron (2019) 
* “[Privacy in Context: Technology, Policy, and the Integrity of Social Life](https://www.sup.org/books/title/?id=8862)” by Helen Nissenbaum (2009)

### Other:

* “[Large Libel Models? Liability for AI Output](https://www2.law.ucla.edu/volokh/ailibel.pdf )” by Eugene Volokh (draft 2023)
* “[Section 230 Won’t Protect ChatGPT](https://www.lawfareblog.com/section-230-wont-protect-chatgpt)” by Matt Perault (2023)

## Interdisciplinary

* “[Ethical and social risks of harm from Language Models](https://arxiv.org/abs/2112.04359)” by Laura Weidinger, et. al. (2021)
* [Algorithms that remember: model inversion attacks and data protection law | Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences](https://royalsocietypublishing.org/doi/10.1098/rsta.2018.0083)
* “[Provable Copyright Protection for Generative Models](https://arxiv.org/abs/2302.10870)” by Nikhil Vyas, Sham Kakade, and Boaz Barak (2023)

## Technical

### Language Models

* “[Eight Things to Know about Large Language Models](https://arxiv.org/abs/2304.00612)” by Sam Bowman (2023)
* “[A Primer in BERTology: What we know about how BERT works](https://arxiv.org/abs/2002.12327)” by Anna Rogers, Olga Kovaleva, and Anna Rumshisky (2020)
* https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/
* What Does it Mean for a Language Model to Preserve Privacy? [arxiv][FAccT]

## Privacy

### Training data extraction
* “[Extracting Training Data from Large Language Models](https://www.usenix.org/conference/usenixsecurity21/presentation/carlini-extracting)” by Nicholas Carlini, et al. (2021)
* [blog](https://bair.berkeley.edu/blog/2020/12/20/lmmem/) [video](https://www.usenix.org/conference/usenixsecurity21/presentation/carlini-extracting)
* “[Deduplicating Training Data Makes Language Models Better](https://aclanthology.org/2022.acl-long.577/)” by Katherine Lee, Daphne Ippolito, Andrew Nystrom, Chiyuan Zhang, Douglas Eck, Chris Callison-Burch, and Nicholas Carlini (2022)
* “[Quantifying Memorization Across Neural Language Models](https://arxiv.org/abs/2202.07646)” by Nicholas Carlini, Daphne Ippolito, Matthew Jagielski, Katherine Lee, Florian Tramer, and Chiyuan Zhang (2022)

### Membership Inference

* “[Membership Inference Attacks against Machine Learning Models](https://ieeexplore.ieee.org/abstract/document/7958568)” by Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov (2017)
* “[Membership Inference Attacks From First Principles](https://arxiv.org/abs/2112.03570)” by Nicholas Carlini, Steve Chien, Milad Nasr, Shuang Song, Andreas Terzis, and Florian Tramer (2021)
* “[Label-Only Membership Inference Attacks](http://proceedings.mlr.press/v139/choquette-choo21a/choquette-choo21a.pdf)” by Christopher A. Choquette-Choo, Florian Tramer, Nicholas Carlini, and Nicolas Papernot (2021)

### Differential Privacy

* “[Auditing Differentially Private Machine Learning: How Private is Private SGD?](https://proceedings.neurips.cc/paper/2020/file/fc4ddc15f9f4b4b06ef7844d6bb53abf-Paper.pdf)”  by Matthew Jagielski, Jonathan Ullman, and Alina Oprea (2020)
* “[Deep Learning with Differential Privacy](https://dl.acm.org/doi/abs/10.1145/2976749.2978318) by Martin Abadi, Andy Chu, Ian Goodfellow, H. Brendan McMahan, Ilya Mironov, Kunal Talwar, Li Zhang (2016)
* “[Toward Training at ImageNet Scale with Differential Privacy](https://arxiv.org/abs/2201.12328) by Alexey Kurakin, Shuang Song, Steve Chien, Roxana Geambasu, Andreas Terzis, and Abhradeep Thakurta (2022)
* “[Considerations for Differentially Private Learning with Large-Scale Public Pretraining](https://arxiv.org/abs/2212.06470)” by Florian Tramèr, Gautam Kamath, Nicholas Carlini (2022)
* “[Training Text-to-Text Transformers with Privacy Guarantees](https://aclanthology.org/2022.findings-acl.171.pdf) by Natalia Ponomareva Jasmijn Bastings Sergei Vassilvitskii (2022)


## General

* “[Accountability in an Algorithmic Society: Relationality, Responsibility, and Robustness in Machine Learning](https://arxiv.org/abs/2202.05338)” by A. Feder Cooper, Emanuel Moss, Benjamin Laufer and Helen Nissenbaum (2022)

## In the news

* [Samsung workers made a major error by using ChatGPT ](https://www.techradar.com/news/samsung-workers-leaked-company-secrets-by-using-chatgpt)
* [OpenAI threatened with landmark defamation lawsuit over ChatGPT false claims](https://arstechnica.com/tech-policy/2023/04/openai-may-be-sued-after-chatgpt-falsely-says-aussie-mayor-is-an-ex-con/)
* [Getty Images is suing the creators of AI art tool Stable Diffusion for scraping its content - The Verge](https://www.theverge.com/2023/1/17/23558516/ai-art-copyright-stable-diffusion-getty-images-lawsuit)
* [UK Government axes plans to broaden existing text and data mining exception - The IPKat](https://ipkitten.blogspot.com/2023/02/uk-government-axes-plans-to-broaden.html)
* [The UK government moves forward with a text and data mining exception for all purposes - Kluwer Copyright Blog](https://copyrightblog.kluweriplaw.com/2022/08/24/the-uk-government-moves-forward-with-a-text-and-data-mining-exception-for-all-purposes/)
* [Israel Ministry of Justice Issues Opinion Supporting the Use of Copyrighted Works for Machine Learning](https://www.project-disco.org/intellectual-property/011823-israel-ministry-of-justice-issues-opinion-supporting-the-use-of-copyrighted-works-for-machine-learning/)
* [Copyright in generative deep learning | Data & Policy | Cambridge Core ](https://www.cambridge.org/core/journals/data-and-policy/article/copyright-in-generative-deep-learning/C401539FDF79A6AC6CEE8C5256508B5E)
* “The 13,000-member Authors Guild in New York City–the United States’ leading writer-advocacy organization–has today (March 1) issued an update to its [model trade book contract](https://authorsguild.org/resource/model-trade-book-contract/) and [literary translation model contract](https://authorsguild.org/resource/translation-model-contract/) with a new clause that prohibits publishers from using or sublicensing books under contract to train “artificial intelligence” technologies.”
* ['AI' at Bologna: The Hair-Raising Topic of 2023?](https://publishingperspectives.com/2023/03/ai-at-bologna-the-hair-raising-topic-of-2023/)


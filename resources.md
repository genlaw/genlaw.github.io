---
title: "GenLaw '23: Resources"
lang: en-US
main-id: resources
---


## Legal
### Copyright

* [Artificial Intelligence’s Fair Use Crisis](https://www.bensobel.org/files/articles/41.1_Sobel-FINAL.pdf) by Ben Sobel (2017)
* [Foundation Models and Fair Use](https://arxiv.org/abs/2303.15715) by Peter Henderson, Xuechen Li, Dan Jurafsky, Tatsunori Hashimoto, Mark A. Lemley, and Percy Liang (2023)
* [LIBRARY OF CONGRESS Copyright Office 37 CFR Part 202 Copyright Registration Guidance: Works Containing Material Generated by Art](https://public-inspection.federalregister.gov/2023-05321.pdf) (2023)
* [Fair Learning](https://texaslawreview.org/fair-learning/) by Mark A. Lemley and Bryan Casey (2021)
* [How Copyright Law Can Fix Artificial Intelligence's Implicit Bias Problem](https://digitalcommons.law.uw.edu/wlr/vol93/iss2/2) by Amanda Levendowski (2018)
* [There’s No Such Thing as a Computer-Authored Work—And It's a Good Thing, Too](https://james.grimmelmann.net/files/articles/computer-authored-works.pdf) by James Grimmelmann (2016)

### Privacy

* [A taxonomy of privacy](https://scholarship.law.upenn.edu/cgi/viewcontent.cgi?article=1376&context=penn_law_review) by Daniel Solove (2006) 
* [Privacy Harms](https://heinonline.org/HOL/LandingPage?handle=hein.journals/bulr102&div=20&id=&page=) by Danielle Citron and Daniel Solove (2022) 
* [Deep Fakes: A Looming Challenge for Privacy, Democracy, and National Security](https://heinonline.org/HOL/LandingPage?handle=hein.journals/calr107&div=51&id=&page=) by Bobby Chesney and Danielle Citron (2019) 
* [Privacy in Context: Technology, Policy, and the Integrity of Social Life](https://www.sup.org/books/title/?id=8862) by Helen Nissenbaum (2009)

### Other

* [Large Libel Models? Liability for AI Output](https://www2.law.ucla.edu/volokh/ailibel.pdf ) by Eugene Volokh (draft 2023)
* [Section 230 Won’t Protect ChatGPT](https://www.lawfareblog.com/section-230-wont-protect-chatgpt) by Matt Perault (2023)

## Interdisciplinary

* [Algorithms that remember: model inversion attacks and data protection law](https://royalsocietypublishing.org/doi/10.1098/rsta.2018.0083) by Michael Veale, Reuben Binns, and Lilian Edwards (2018)
* [Ethical and social risks of harm from Language Models](https://arxiv.org/abs/2112.04359) by Laura Weidinger, John Mellor, Maribeth Rauh, Conor Griffin, Jonathan Uesato, Po-Sen Huang, Myra Cheng, Mia Glaese, Borja Balle, Atoosa Kasirzadeh, Zac Kenton, Sasha Brown, Will Hawkins, Tom Stepleton, Courtney Biles, Abeba Birhane, Julia Haas, Laura Rimell, Lisa Anne Hendricks, William Isaac, Sean Legassick, Geoffrey Irving, and Iason Gabriel (2021)
* [Accountability in an Algorithmic Society: Relationality, Responsibility, and Robustness in Machine Learning](https://arxiv.org/abs/2202.05338) by A. Feder Cooper, Emanuel Moss, Benjamin Laufer and Helen Nissenbaum (2022)
* [Provable Copyright Protection for Generative Models](https://arxiv.org/abs/2302.10870) by Nikhil Vyas, Sham Kakade, and Boaz Barak (2023)


## Technical

### Language Models

* [Eight Things to Know about Large Language Models](https://arxiv.org/abs/2304.00612) by Sam Bowman (2023)
* [A Primer in BERTology: What we know about how BERT works](https://arxiv.org/abs/2002.12327) by Anna Rogers, Olga Kovaleva, and Anna Rumshisky (2020)
* [What Is ChatGPT Doing … and Why Does It Work?](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/) by Stephen Wolfram (2023)
* [What Does it Mean for a Language Model to Preserve Privacy?](https://dl.acm.org/doi/fullHtml/10.1145/3531146.3534642) by  Hannah Brown, Katherine Lee, Fatemehsadat Mireshghallah, Reza Shokri, and Florian Tramèr (2022)
* [Prompting Guide](https://www.promptingguide.ai/) by DAIR.AI (2022)

## Privacy

### Training data extraction
* [Extracting Training Data from Large Language Models](https://www.usenix.org/conference/usenixsecurity21/presentation/carlini-extracting) by Nicholas Carlini, Florian Tramèr, Eric Wallace,  Matthew Jagielski, Ariel Herbert-Voss, Katherine Lee, Adam Roberts, Tom Brown, Dawn Song, Úlfar Erlingsson, Alina Oprea, and Colin Raffel (2021), [blog](https://bair.berkeley.edu/blog/2020/12/20/lmmem/){.inline}, [video](https://www.usenix.org/conference/usenixsecurity21/presentation/carlini-extracting){.inline}
* [Deduplicating Training Data Makes Language Models Better](https://aclanthology.org/2022.acl-long.577/) by Katherine Lee, Daphne Ippolito, Andrew Nystrom, Chiyuan Zhang, Douglas Eck, Chris Callison-Burch, and Nicholas Carlini (2022)
* [Quantifying Memorization Across Neural Language Models](https://arxiv.org/abs/2202.07646) by Nicholas Carlini, Daphne Ippolito, Matthew Jagielski, Katherine Lee, Florian Tramer, and Chiyuan Zhang (2022)

### Membership Inference

* [Membership Inference Attacks against Machine Learning Models](https://ieeexplore.ieee.org/abstract/document/7958568) by Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov (2017)
* [Membership Inference Attacks From First Principles](https://arxiv.org/abs/2112.03570) by Nicholas Carlini, Steve Chien, Milad Nasr, Shuang Song, Andreas Terzis, and Florian Tramer (2021)
* [Label-Only Membership Inference Attacks](http://proceedings.mlr.press/v139/choquette-choo21a/choquette-choo21a.pdf) by Christopher A. Choquette-Choo, Florian Tramer, Nicholas Carlini, and Nicolas Papernot (2021)

### Differential Privacy

* [Auditing Differentially Private Machine Learning: How Private is Private SGD?](https://proceedings.neurips.cc/paper/2020/file/fc4ddc15f9f4b4b06ef7844d6bb53abf-Paper.pdf) by Matthew Jagielski, Jonathan Ullman, and Alina Oprea (2020)
* [Deep Learning with Differential Privacy](https://dl.acm.org/doi/abs/10.1145/2976749.2978318) by Martin Abadi, Andy Chu, Ian Goodfellow, H. Brendan McMahan, Ilya Mironov, Kunal Talwar, Li Zhang (2016)
* [Toward Training at ImageNet Scale with Differential Privacy](https://arxiv.org/abs/2201.12328) by Alexey Kurakin, Shuang Song, Steve Chien, Roxana Geambasu, Andreas Terzis, and Abhradeep Thakurta (2022)
* [Considerations for Differentially Private Learning with Large-Scale Public Pretraining](https://arxiv.org/abs/2212.06470) by Florian Tramèr, Gautam Kamath, Nicholas Carlini (2022)
* [Training Text-to-Text Transformers with Privacy Guarantees](https://aclanthology.org/2022.findings-acl.171.pdf) by Natalia Ponomareva Jasmijn Bastings Sergei Vassilvitskii (2022)


## Ongoing litigation

* [Doe 1 et al. v. GitHub, Inc. et al.](https://githubcopilotlitigation.com/) GitHub Copilot class action lawsuit
* [Andersen et al. v. Stability AI Ltd. et al.](https://stablediffusionlitigation.com/) Stable Diffusion  class action lawsuit


## In the news

* [Samsung workers made a major error by using ChatGPT](https://www.techradar.com/news/samsung-workers-leaked-company-secrets-by-using-chatgpt) by Lewis Maddison for _TechRadar_ (2023)
* [OpenAI threatened with landmark defamation lawsuit over ChatGPT false claims](https://arstechnica.com/tech-policy/2023/04/openai-may-be-sued-after-chatgpt-falsely-says-aussie-mayor-is-an-ex-con/) by Ashley Belanger for _Ars Technica_ (2023)
* [Getty Images is suing the creators of AI art tool Stable Diffusion for scraping its content](https://www.theverge.com/2023/1/17/23558516/ai-art-copyright-stable-diffusion-getty-images-lawsuit) by James Vincent for _The Verge_ (2023)
* [UK Government axes plans to broaden existing text and data mining exception](https://ipkitten.blogspot.com/2023/02/uk-government-axes-plans-to-broaden.html) by Eleonora Rosati for _IPKat_ (2023)
* [The UK government moves forward with a text and data mining exception for all purposes](https://copyrightblog.kluweriplaw.com/2022/08/24/the-uk-government-moves-forward-with-a-text-and-data-mining-exception-for-all-purposes/) by Alina Trapova and João Pedro Quintais for _Kluwer Copyright Blog_ (2022)
* [Israel Ministry of Justice Issues Opinion Supporting the Use of Copyrighted Works for Machine Learning](https://www.project-disco.org/intellectual-property/011823-israel-ministry-of-justice-issues-opinion-supporting-the-use-of-copyrighted-works-for-machine-learning/) by Jonathan Band for _The Disruptive Competition Project_ (2023)
* [Copyright in generative deep learning](https://www.cambridge.org/core/journals/data-and-policy/article/copyright-in-generative-deep-learning/C401539FDF79A6AC6CEE8C5256508B5E) by Giorgio Franceschelli and Mirco Musolesi for _Data & Policy_ (2022)
* ['AI' at Bologna: The Hair-Raising Topic of 2023?](https://publishingperspectives.com/2023/03/ai-at-bologna-the-hair-raising-topic-of-2023/) <q>The 13,000-member Authors Guild in New York City–the United States’ leading writer-advocacy organization–has today (March 1) issued an update to its [model trade book contract](https://authorsguild.org/resource/model-trade-book-contract/) and [literary translation model contract](https://authorsguild.org/resource/translation-model-contract/) with a new clause that prohibits publishers from using or sublicensing books under contract to train “artificial intelligence” technologies.</q> by Porter Anderson for _Publishing Perspectives_ (2023)